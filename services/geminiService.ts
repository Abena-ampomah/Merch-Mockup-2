
import { GoogleGenAI, Modality } from "@google/genai";
import type { AspectRatio } from "../types";

const fileToGenerativePart = async (file: File) => {
  const base64EncodedDataPromise = new Promise<string>((resolve) => {
    const reader = new FileReader();
    reader.onloadend = () => {
        if (reader.result) {
            resolve((reader.result as string).split(',')[1]);
        } else {
            resolve('');
        }
    };
    reader.readAsDataURL(file);
  });
  return {
    inlineData: { data: await base64EncodedDataPromise, mimeType: file.type },
  };
};

const imageUrlToGenerativePart = async (url: string) => {
    const response = await fetch(url);
    if (!response.ok) {
        throw new Error(`Failed to fetch image from ${url}: ${response.statusText}`);
    }
    const blob = await response.blob();
    const base64EncodedDataPromise = new Promise<string>((resolve) => {
        const reader = new FileReader();
        reader.onloadend = () => {
           if (reader.result) {
               resolve((reader.result as string).split(',')[1]);
           } else {
               resolve('');
           }
        };
        reader.readAsDataURL(blob);
    });
    return {
        inlineData: { data: await base64EncodedDataPromise, mimeType: blob.type },
    };
};

export const removeLogoBackground = async (logoFile: File): Promise<File> => {
  if (!process.env.API_KEY) {
    throw new Error("API_KEY environment variable not set.");
  }
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  const logoImagePart = await fileToGenerativePart(logoFile);
  const textPart = { text: "Remove the background of this image, making it transparent. The subject should be perfectly preserved. Output a PNG file." };

  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash-image',
    contents: {
      parts: [logoImagePart, textPart],
    },
    config: {
      responseModalities: [Modality.IMAGE],
    },
  });

  for (const part of response.candidates[0].content.parts) {
    if (part.inlineData) {
      const base64Data = part.inlineData.data;
      const mimeType = part.inlineData.mimeType; // Should be image/png
      const dataUrl = `data:${mimeType};base64,${base64Data}`;
      
      const blob = await (await fetch(dataUrl)).blob();
      const originalName = logoFile.name.substring(0, logoFile.name.lastIndexOf('.'));
      const newFileName = `${originalName}-no-bg.png`;

      return new File([blob], newFileName, { type: mimeType });
    }
  }

  throw new Error("Background removal failed: No image was returned by the API.");
};


export const generateMerchMockup = async (
  productImageUrl: string,
  logoFile: File,
  prompt: string,
  modelImageUrl?: string
): Promise<string> => {
  if (!process.env.API_KEY) {
    throw new Error("API_KEY environment variable not set.");
  }

  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  const textPart = { text: prompt };
  const productImagePart = await imageUrlToGenerativePart(productImageUrl);
  const logoImagePart = await fileToGenerativePart(logoFile);

  // Fix: Explicitly type `parts` to allow both image and text parts.
  // TypeScript was inferring the type as an array of only image parts,
  // causing an error when trying to push a text part.
  const parts: ({ inlineData: { data: string; mimeType: string; }; } | { text: string; })[] = [
    productImagePart,
    logoImagePart,
  ];

  if (modelImageUrl) {
    const modelImagePart = await imageUrlToGenerativePart(modelImageUrl);
    parts.unshift(modelImagePart); // Place model image first for context
  }
  
  parts.push(textPart); // Text prompt last


  const response = await ai.models.generateContent({
    model: 'gemini-2.5-flash-image',
    contents: {
      parts: parts,
    },
    config: {
      responseModalities: [Modality.IMAGE],
    },
  });

  for (const part of response.candidates[0].content.parts) {
    if (part.inlineData) {
      return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
    }
  }

  throw new Error("No image was generated by the API.");
};

export const editImage = async (imageFile: File, prompt: string): Promise<string> => {
    if (!process.env.API_KEY) {
        throw new Error("API_KEY environment variable not set.");
    }
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
    const imagePart = await fileToGenerativePart(imageFile);
    const textPart = { text: prompt };

    const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash-image',
        contents: { parts: [imagePart, textPart] },
        config: { responseModalities: [Modality.IMAGE] },
    });

    for (const part of response.candidates[0].content.parts) {
        if (part.inlineData) {
            return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
        }
    }

    throw new Error("Image editing failed: No image was returned by the API.");
};

export const generateImage = async (prompt: string, aspectRatio: AspectRatio): Promise<string> => {
    if (!process.env.API_KEY) {
        throw new Error("API_KEY environment variable not set.");
    }
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

    const response = await ai.models.generateImages({
        model: 'imagen-4.0-generate-001',
        prompt: prompt,
        config: {
            numberOfImages: 1,
            outputMimeType: 'image/png',
            aspectRatio: aspectRatio,
        },
    });

    const base64ImageBytes = response.generatedImages[0].image.imageBytes;
    return `data:image/png;base64,${base64ImageBytes}`;
};

export const generateVideo = async (
    imageFile: File,
    prompt: string,
    aspectRatio: '16:9' | '9:16',
    setLoadingMessage: (message: string) => void
): Promise<string> => {
    if (!process.env.API_KEY) {
        throw new Error("API_KEY environment variable not set. Please select a key for Veo.");
    }
    // Create a new instance right before the API call to ensure the latest key is used.
    const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

    const { data: base64EncodedData, mimeType } = (await fileToGenerativePart(imageFile)).inlineData;

    setLoadingMessage("Starting video generation...");
    let operation = await ai.models.generateVideos({
        model: 'veo-3.1-fast-generate-preview',
        prompt,
        image: {
            imageBytes: base64EncodedData,
            mimeType: mimeType,
        },
        config: {
            numberOfVideos: 1,
            resolution: '720p',
            aspectRatio: aspectRatio
        }
    });

    let pollCount = 0;
    const pollMessages = [
        "Warming up the AI director...",
        "Setting up the virtual cameras...",
        "Rendering the first few frames...",
        "Adding special effects...",
        "Finalizing the scene...",
        "Almost there, just polishing the final cut..."
    ];

    while (!operation.done) {
        setLoadingMessage(pollMessages[pollCount % pollMessages.length] + ` (This can take a few minutes)`);
        pollCount++;
        await new Promise(resolve => setTimeout(resolve, 10000));
        operation = await ai.operations.getVideosOperation({ operation: operation });
    }

    setLoadingMessage("Fetching your video...");
    const downloadLink = operation.response?.generatedVideos?.[0]?.video?.uri;
    if (!downloadLink) {
        throw new Error("Video generation completed, but no download link was found.");
    }

    const response = await fetch(`${downloadLink}&key=${process.env.API_KEY}`);
    if (!response.ok) {
        const errorBody = await response.text();
        console.error("Video download failed:", errorBody);
        throw new Error(`Failed to download video: ${response.statusText}`);
    }
    const videoBlob = await response.blob();
    return URL.createObjectURL(videoBlob);
};